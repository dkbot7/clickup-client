# üî¨ Pesquisa T√©cnica: Funcionalidades Estruturais

**Sistema Kaloi - ClickUp Client**

Pesquisa sobre funcionalidades avan√ßadas e estruturais para otimizar o cliente ClickUp.

---

## üìã √çndice

1. [Pagina√ß√£o Autom√°tica](#pagina√ß√£o-autom√°tica)
2. [Retry e Backoff Autom√°tico](#retry-e-backoff-autom√°tico)
3. [Batch Operations](#batch-operations)
4. [Async/Await](#asyncawait)
5. [Implementa√ß√£o Recomendada](#implementa√ß√£o-recomendada)
6. [Refer√™ncias](#refer√™ncias)

---

## üîÑ Pagina√ß√£o Autom√°tica

### Resumo

A API do ClickUp limita respostas a **100 itens por p√°gina**. Para recuperar grandes volumes de dados, √© necess√°rio implementar pagina√ß√£o autom√°tica.

### Como Funciona na API ClickUp

**Par√¢metros de Pagina√ß√£o:**
- `page`: N√∫mero da p√°gina (come√ßa em 0)
- `limit`: M√°ximo de itens por p√°gina (m√°ximo: 100)

**Response:**
```json
{
  "tasks": [...],
  "last_page": false  // true quando n√£o h√° mais p√°ginas
}
```

### Implementa√ß√£o Recomendada

```python
def get_all_tasks(self, list_id: str, **filters) -> List[Dict]:
    """
    Busca todas as tasks com pagina√ß√£o autom√°tica.

    Args:
        list_id: ID da list
        **filters: Filtros adicionais

    Returns:
        Lista completa de tasks
    """
    all_tasks = []
    page = 0

    while True:
        # Buscar p√°gina atual
        response = self._request(
            "GET",
            f"list/{list_id}/task",
            params={"page": page, **filters}
        )

        if not response or "tasks" not in response:
            break

        tasks = response["tasks"]
        all_tasks.extend(tasks)

        # Verificar se h√° mais p√°ginas
        if response.get("last_page", False) or len(tasks) < 100:
            break

        page += 1

    return all_tasks
```

### Estrat√©gias de Pagina√ß√£o

#### 1. **Eager Loading** (padr√£o acima)
- Carrega todos os dados de uma vez
- **Vantagem**: Simples, todos os dados dispon√≠veis imediatamente
- **Desvantagem**: Alto uso de mem√≥ria para grandes datasets

#### 2. **Lazy Loading com Generator**
```python
def iter_tasks(self, list_id: str, **filters):
    """
    Itera sobre tasks usando generator (lazy loading).

    Yields:
        Dict: Task individual
    """
    page = 0

    while True:
        response = self._request(
            "GET",
            f"list/{list_id}/task",
            params={"page": page, **filters}
        )

        if not response or "tasks" not in response:
            break

        tasks = response["tasks"]

        for task in tasks:
            yield task

        if response.get("last_page", False) or len(tasks) < 100:
            break

        page += 1

# Uso
for task in client.iter_tasks("list_id"):
    process_task(task)
```

**Vantagens:**
- Baixo uso de mem√≥ria
- Processa dados conforme carrega
- Ideal para grandes volumes

#### 3. **Chunked Loading**
```python
def get_tasks_chunked(self, list_id: str, chunk_size: int = 5, **filters):
    """
    Carrega tasks em chunks (grupos de p√°ginas).

    Args:
        list_id: ID da list
        chunk_size: N√∫mero de p√°ginas por chunk
        **filters: Filtros

    Yields:
        List[Dict]: Chunk de tasks
    """
    page = 0

    while True:
        chunk = []

        for _ in range(chunk_size):
            response = self._request(
                "GET",
                f"list/{list_id}/task",
                params={"page": page, **filters}
            )

            if not response or "tasks" not in response:
                break

            chunk.extend(response["tasks"])

            if response.get("last_page", False):
                yield chunk
                return

            page += 1

        if chunk:
            yield chunk
        else:
            break
```

### Limita√ß√µes

- **M√°ximo de 100 itens por p√°gina** (n√£o configur√°vel)
- **Pagina√ß√£o baseada em p√°gina**, n√£o cursor
- **N√£o h√° total_pages** na resposta (apenas `last_page`)

---

## üîÅ Retry e Backoff Autom√°tico

### Resumo

A API do ClickUp tem **rate limits** de:
- **100 requisi√ß√µes/min** (Free, Unlimited, Business)
- **1000 requisi√ß√µes/min** (Business Plus)

Responde com **HTTP 429** quando excedido.

### Implementa√ß√£o com urllib3.Retry

```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class KaloiClickUpClient:
    def __init__(self):
        self.session = requests.Session()

        # Configurar retry autom√°tico
        retries = Retry(
            total=5,  # M√°ximo de 5 tentativas
            backoff_factor=1,  # Fator de backoff exponencial
            status_forcelist=[429, 500, 502, 503, 504],  # Status para retry
            allowed_methods=["GET", "POST", "PUT", "DELETE"]  # M√©todos
        )

        adapter = HTTPAdapter(max_retries=retries)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def _request(self, method: str, endpoint: str, **kwargs):
        """Faz requisi√ß√£o com retry autom√°tico."""
        url = f"{self.base_url}/{endpoint}"
        response = self.session.request(method, url, **kwargs)
        response.raise_for_status()
        return response.json()
```

### C√°lculo do Backoff

Com `backoff_factor=1`, os delays s√£o:
- 1¬™ tentativa: 0s (imediato)
- 2¬™ tentativa: 0.5s
- 3¬™ tentativa: 1s
- 4¬™ tentativa: 2s
- 5¬™ tentativa: 4s
- 6¬™ tentativa: 8s

**F√≥rmula:**
```
delay = backoff_factor * (2 ** (retry_number - 1))
```

### Implementa√ß√£o com backoff Library

```python
import backoff
import requests

class KaloiClickUpClient:
    @backoff.on_exception(
        backoff.expo,  # Exponential backoff
        requests.exceptions.RequestException,
        max_tries=5,
        giveup=lambda e: e.response is not None and e.response.status_code < 500
    )
    def _request(self, method: str, endpoint: str, **kwargs):
        """Requisi√ß√£o com backoff exponencial."""
        url = f"{self.base_url}/{endpoint}"
        response = requests.request(method, url, **kwargs)
        response.raise_for_status()
        return response.json()
```

### Rate Limiting Proativo

```python
from ratelimit import limits, sleep_and_retry

class KaloiClickUpClient:
    CALLS_PER_MINUTE = 100  # Ajustar conforme plano

    @sleep_and_retry
    @limits(calls=CALLS_PER_MINUTE, period=60)
    def _request(self, method: str, endpoint: str, **kwargs):
        """Requisi√ß√£o com rate limiting proativo."""
        url = f"{self.base_url}/{endpoint}"
        response = requests.request(method, url, **kwargs)
        response.raise_for_status()
        return response.json()
```

### Tratamento de Retry-After Header

```python
def _request(self, method: str, endpoint: str, **kwargs):
    """Requisi√ß√£o respeitando Retry-After header."""
    url = f"{self.base_url}/{endpoint}"

    while True:
        response = requests.request(method, url, **kwargs)

        if response.status_code == 429:
            # Verificar header Retry-After
            retry_after = response.headers.get("Retry-After")

            if retry_after:
                wait_time = int(retry_after)
                print(f"[yellow]‚è± Rate limit atingido. Aguardando {wait_time}s...[/yellow]")
                time.sleep(wait_time)
                continue
            else:
                # Backoff padr√£o se n√£o houver header
                time.sleep(60)
                continue

        response.raise_for_status()
        return response.json()
```

---

## üì¶ Batch Operations

### Resumo

**Importante:** A API do ClickUp **N√ÉO tem endpoint oficial de batch/bulk operations** para criar ou atualizar m√∫ltiplas tasks de uma vez.

### Limita√ß√µes Atuais

- N√£o h√° endpoint `POST /tasks` (bulk create)
- N√£o h√° endpoint `PUT /tasks` (bulk update)
- Cada task deve ser criada/atualizada individualmente

### Estrat√©gias de Otimiza√ß√£o

#### 1. **Concurrent Requests com Threading**

```python
import concurrent.futures
from typing import List, Dict

class KaloiClickUpClient:
    def create_tasks_batch(
        self,
        list_id: str,
        tasks: List[Dict],
        max_workers: int = 5
    ) -> List[Dict]:
        """
        Cria m√∫ltiplas tasks concorrentemente.

        Args:
            list_id: ID da list
            tasks: Lista de dicts com dados das tasks
            max_workers: M√°ximo de threads concorrentes

        Returns:
            Lista de tasks criadas
        """
        def create_task(task_data):
            return self.create_task(list_id, **task_data)

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(create_task, tasks))

        return results
```

**Vantagens:**
- Aproveita I/O wait
- Mais r√°pido que sequencial
- Simples de implementar

**Desvantagens:**
- Ainda faz N requisi√ß√µes
- Pode estourar rate limit rapidamente

#### 2. **Rate-Limited Batch Processing**

```python
from ratelimit import limits, sleep_and_retry
from tqdm import tqdm

class KaloiClickUpClient:
    @sleep_and_retry
    @limits(calls=90, period=60)  # 90 chamadas/min (margem de seguran√ßa)
    def _create_task_rate_limited(self, list_id: str, **task_data):
        """Cria task com rate limit."""
        return self.create_task(list_id, **task_data)

    def create_tasks_batch(
        self,
        list_id: str,
        tasks: List[Dict],
        show_progress: bool = True
    ) -> List[Dict]:
        """
        Cria tasks em lote respeitando rate limit.

        Args:
            list_id: ID da list
            tasks: Lista de tasks
            show_progress: Mostrar barra de progresso

        Returns:
            Lista de tasks criadas
        """
        results = []

        iterator = tqdm(tasks, desc="Criando tasks") if show_progress else tasks

        for task_data in iterator:
            result = self._create_task_rate_limited(list_id, **task_data)
            results.append(result)

        return results
```

#### 3. **Async Batch com asyncio** (veja se√ß√£o async)

```python
import asyncio
import httpx

class AsyncKaloiClickUpClient:
    async def create_tasks_batch(
        self,
        list_id: str,
        tasks: List[Dict]
    ) -> List[Dict]:
        """Cria tasks assincronamente."""
        async with httpx.AsyncClient() as client:
            tasks_coros = [
                self._create_task_async(client, list_id, task_data)
                for task_data in tasks
            ]
            results = await asyncio.gather(*tasks_coros)

        return results
```

### Recomenda√ß√µes

1. **Para < 10 tasks:** Sequencial √© suficiente
2. **Para 10-100 tasks:** Threading com rate limiting
3. **Para > 100 tasks:** Async com controle de concorr√™ncia

---

## ‚ö° Async/Await

### Resumo

Implementar vers√£o ass√≠ncrona do cliente para alto desempenho com m√∫ltiplas requisi√ß√µes concorrentes.

### Bibliotecas Recomendadas

- **httpx**: HTTP client async/sync
- **aiohttp**: Async HTTP client/server
- **asyncio**: Framework async do Python

### Implementa√ß√£o com httpx

```python
import asyncio
import httpx
from typing import Optional, Dict, Any

class AsyncKaloiClickUpClient:
    """Cliente ClickUp ass√≠ncrono."""

    def __init__(
        self,
        token: Optional[str] = None,
        team_id: Optional[str] = None,
        base_url: str = "https://api.clickup.com/api/v2"
    ):
        self.token = token or os.getenv("CLICKUP_TOKEN")
        self.team_id = team_id or os.getenv("CLICKUP_TEAM_ID")
        self.base_url = base_url

        self.headers = {
            "Authorization": self.token,
            "Content-Type": "application/json"
        }

    async def _request(
        self,
        client: httpx.AsyncClient,
        method: str,
        endpoint: str,
        **kwargs
    ) -> Optional[Dict]:
        """
        Faz requisi√ß√£o ass√≠ncrona.

        Args:
            client: Cliente httpx
            method: M√©todo HTTP
            endpoint: Endpoint da API
            **kwargs: Par√¢metros adicionais

        Returns:
            Response JSON ou None
        """
        url = f"{self.base_url}/{endpoint}"

        try:
            response = await client.request(
                method,
                url,
                headers=self.headers,
                **kwargs
            )
            response.raise_for_status()
            return response.json()
        except httpx.HTTPStatusError as e:
            print(f"[red]‚úó HTTP Error: {e}[/red]")
            return None

    async def get_task(self, task_id: str) -> Optional[Dict]:
        """Busca task assincronamente."""
        async with httpx.AsyncClient() as client:
            return await self._request(client, "GET", f"task/{task_id}")

    async def get_tasks(self, list_id: str, **filters) -> Optional[Dict]:
        """Busca tasks assincronamente."""
        async with httpx.AsyncClient() as client:
            return await self._request(
                client,
                "GET",
                f"list/{list_id}/task",
                params=filters
            )

    async def create_task(
        self,
        list_id: str,
        name: str,
        **kwargs
    ) -> Optional[Dict]:
        """Cria task assincronamente."""
        async with httpx.AsyncClient() as client:
            payload = {"name": name, **kwargs}
            return await self._request(
                client,
                "POST",
                f"list/{list_id}/task",
                json=payload
            )
```

### Batch Operations com Async

```python
class AsyncKaloiClickUpClient:
    async def get_multiple_tasks(
        self,
        task_ids: List[str]
    ) -> List[Optional[Dict]]:
        """
        Busca m√∫ltiplas tasks concorrentemente.

        Args:
            task_ids: Lista de IDs

        Returns:
            Lista de tasks
        """
        async with httpx.AsyncClient() as client:
            tasks = [
                self._request(client, "GET", f"task/{task_id}")
                for task_id in task_ids
            ]
            results = await asyncio.gather(*tasks)

        return results

    async def create_multiple_tasks(
        self,
        list_id: str,
        tasks_data: List[Dict]
    ) -> List[Optional[Dict]]:
        """
        Cria m√∫ltiplas tasks concorrentemente.

        Args:
            list_id: ID da list
            tasks_data: Lista de dicts com dados

        Returns:
            Lista de tasks criadas
        """
        async with httpx.AsyncClient() as client:
            tasks = [
                self._request(
                    client,
                    "POST",
                    f"list/{list_id}/task",
                    json=task_data
                )
                for task_data in tasks_data
            ]
            results = await asyncio.gather(*tasks)

        return results
```

### Controle de Concorr√™ncia

```python
import asyncio
from asyncio import Semaphore

class AsyncKaloiClickUpClient:
    async def create_tasks_controlled(
        self,
        list_id: str,
        tasks_data: List[Dict],
        max_concurrent: int = 10
    ) -> List[Optional[Dict]]:
        """
        Cria tasks com controle de concorr√™ncia.

        Args:
            list_id: ID da list
            tasks_data: Dados das tasks
            max_concurrent: M√°ximo de requisi√ß√µes simult√¢neas

        Returns:
            Lista de tasks criadas
        """
        semaphore = Semaphore(max_concurrent)

        async def create_with_limit(task_data):
            async with semaphore:
                async with httpx.AsyncClient() as client:
                    return await self._request(
                        client,
                        "POST",
                        f"list/{list_id}/task",
                        json=task_data
                    )

        tasks = [create_with_limit(data) for data in tasks_data]
        results = await asyncio.gather(*tasks)

        return results
```

### Uso do Cliente Async

```python
# Uso b√°sico
async def main():
    client = AsyncKaloiClickUpClient()

    # Buscar task
    task = await client.get_task("task_id")

    # Criar m√∫ltiplas tasks
    tasks_data = [
        {"name": "Task 1", "description": "Desc 1"},
        {"name": "Task 2", "description": "Desc 2"},
        {"name": "Task 3", "description": "Desc 3"}
    ]

    results = await client.create_multiple_tasks("list_id", tasks_data)
    print(f"Criadas {len(results)} tasks")

# Executar
asyncio.run(main())
```

### Vantagens do Async

- **Performance**: 10-100x mais r√°pido para m√∫ltiplas requisi√ß√µes
- **Escalabilidade**: Suporta centenas de requisi√ß√µes concorrentes
- **Efici√™ncia**: Melhor uso de recursos (CPU, mem√≥ria)

### Desvantagens

- **Complexidade**: C√≥digo mais complexo
- **Debugging**: Mais dif√≠cil de debugar
- **Compatibilidade**: Requer Python 3.7+

---

## üéØ Implementa√ß√£o Recomendada

### Prioridade 1: Retry e Backoff

**Motivo:** Essencial para produ√ß√£o, evita falhas por rate limit

```python
# Adicionar ao client.py existente
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class KaloiClickUpClient:
    def __init__(self):
        # ... c√≥digo existente ...

        # Configurar session com retry
        self.session = requests.Session()
        retries = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        self.session.mount("https://", HTTPAdapter(max_retries=retries))

    def _request(self, method: str, endpoint: str, **kwargs):
        # Usar self.session ao inv√©s de requests diretamente
        url = f"{self.base_url}/{endpoint}"
        response = self.session.request(method, url, **kwargs)
        # ... resto do c√≥digo ...
```

### Prioridade 2: Pagina√ß√£o Autom√°tica

**Motivo:** Crucial para lidar com grandes volumes de dados

```python
# Adicionar m√©todo auxiliar
def get_all_paginated(
    self,
    endpoint: str,
    data_key: str = "tasks",
    **params
) -> List[Dict]:
    """
    Helper gen√©rico para pagina√ß√£o.

    Args:
        endpoint: Endpoint da API
        data_key: Chave dos dados na response
        **params: Par√¢metros da requisi√ß√£o

    Returns:
        Lista completa de items
    """
    all_items = []
    page = 0

    while True:
        params["page"] = page
        response = self._request("GET", endpoint, params=params)

        if not response or data_key not in response:
            break

        items = response[data_key]
        all_items.extend(items)

        if response.get("last_page", False) or len(items) < 100:
            break

        page += 1

    return all_items

# Atualizar get_tasks para usar pagina√ß√£o
def get_tasks(self, list_id: str, paginate: bool = False, **filters):
    """
    Busca tasks de uma list.

    Args:
        list_id: ID da list
        paginate: Se True, busca todas as p√°ginas
        **filters: Filtros

    Returns:
        Dict com tasks ou lista completa se paginate=True
    """
    if paginate:
        return self.get_all_paginated(
            f"list/{list_id}/task",
            data_key="tasks",
            **filters
        )
    else:
        return self._request("GET", f"list/{list_id}/task", params=filters)
```

### Prioridade 3: Batch Helper (Threading)

**Motivo:** Acelera opera√ß√µes em lote sem complexidade do async

```python
import concurrent.futures
from typing import Callable, List, Any

def batch_operation(
    self,
    operation: Callable,
    items: List[Any],
    max_workers: int = 5,
    show_progress: bool = True
) -> List[Any]:
    """
    Executa opera√ß√£o em lote com threading.

    Args:
        operation: Fun√ß√£o a executar (ex: self.create_task)
        items: Lista de argumentos para a fun√ß√£o
        max_workers: Threads concorrentes
        show_progress: Mostrar progresso

    Returns:
        Lista de resultados
    """
    from tqdm import tqdm

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        if show_progress:
            results = list(tqdm(
                executor.map(operation, items),
                total=len(items),
                desc="Processando"
            ))
        else:
            results = list(executor.map(operation, items))

    return results
```

### Prioridade 4: Async Client (Opcional)

**Motivo:** Para casos de alta performance, criar vers√£o async separada

**Arquivo:** `src/clickup_api/async_client.py`

Criar cliente async completo conforme exemplos acima.

---

## üìö Refer√™ncias

### Documenta√ß√£o Oficial

- **ClickUp API Docs**: https://developer.clickup.com/
- **Rate Limits**: https://developer.clickup.com/docs/rate-limits
- **Pagination**: https://clickup.canny.io/feature-requests/p/pagination-through-the-api

### Bibliotecas Python

- **requests**: https://requests.readthedocs.io/
- **urllib3**: https://urllib3.readthedocs.io/
- **httpx**: https://www.python-httpx.org/
- **aiohttp**: https://docs.aiohttp.org/
- **backoff**: https://github.com/litl/backoff
- **ratelimit**: https://github.com/tomasbasham/ratelimit

### Tutoriais e Exemplos

- **Python Requests Retry**: https://scrapeops.io/python-web-scraping-playbook/python-requests-retry-failed-requests/
- **Async HTTP with httpx**: https://www.twilio.com/en-us/blog/asynchronous-http-requests-in-python-with-httpx-and-asyncio
- **ClickUp API with Python**: https://endgrate.com/blog/using-the-clickup-api-to-get-tasks-(with-python-examples)

---

**Criado em:** 2025-10-31
**Autor:** Sistema Kaloi
**Status:** ‚úÖ Completo
